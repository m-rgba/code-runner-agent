{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e563cc7-4746-4cef-a6fb-aa4c1b80ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken==0.8.0 wandb==0.19.6 weave==0.51.33 docker==7.1.0 openai==1.61.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1109ed9-4c0d-4838-800a-8c8478110bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docker\n",
    "import re\n",
    "import tiktoken\n",
    "import wandb\n",
    "import weave\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI() # OpenAI gets the API key from the env var\n",
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ae08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create containers on network\n",
    "container_name = \"nbtest_wandb\"\n",
    "try:\n",
    "    container = docker_client.containers.get(container_name)\n",
    "except docker.errors.NotFound:\n",
    "    # Ensure network exists\n",
    "    network_name = \"wandb_network\"\n",
    "    try:\n",
    "        network = docker_client.networks.get(network_name)\n",
    "    except docker.errors.NotFound:\n",
    "        network = docker_client.networks.create(network_name)\n",
    "\n",
    "    # Create container\n",
    "    container = docker_client.containers.run(\n",
    "        image=\"code-runner-client\",\n",
    "        name=container_name,\n",
    "        shm_size=\"512mb\",\n",
    "        restart_policy={\"Name\": \"unless-stopped\"},\n",
    "        network=network_name,\n",
    "        detach=True,\n",
    "        command=[\"/bin/sh\", \"-c\", \"sleep infinity\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start: Question / prompt\n",
    "question = \"\"\"\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63796e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Generate title\n",
    "system_prompt = \"\"\"\n",
    "You are an AI that generates concise, descriptive titles based on the given question.\n",
    "Your response must be in the format: <title>Generated title here</title>. \"\n",
    "Keep the title brief and relevant to the question.\n",
    "\n",
    "Title examples:\n",
    "Question: \"What are the best practices for securing a FastAPI backend?\"\n",
    "<title>What Securing FastAPI best practices</title>\n",
    "\n",
    "Question: \"What are the key considerations when designing an LLM evaluation framework?\"\n",
    "<title>Designing an LLM eval framework</title>\n",
    "\n",
    "Question: \"How do I optimize OpenAI API costs for large-scale applications?\"\n",
    "<title>Optimizing OpenAI API costs</title>\n",
    "\"\"\".strip()\n",
    "\n",
    "oai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "completion_response = oai_response.choices[0].message.content\n",
    "\n",
    "pattern = r'<title>(.*?)</title>'\n",
    "title = re.findall(pattern, completion_response)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee929201",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Generate plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228dd81-0b73-46ce-a193-eb1274c5caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3) Loop\n",
    "- Generate response \n",
    "- Parse actions\n",
    "- 1. Run code \n",
    "- 2. Get output\n",
    "- Check if complete <answer>\n",
    "- Check if broken <restart_server></restart_server>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55a5ec-f160-4c94-8a30-2497d3bae9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def run_container_command(container):\n",
    "#     exec_result = container.exec_run(\n",
    "#         cmd=[\"python\", \"-c\", \"print('Hello, World!')\"], stdout=True, stderr=True\n",
    "#     )\n",
    "#     return exec_result.output.decode(\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
