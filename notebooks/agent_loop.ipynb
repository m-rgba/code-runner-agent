{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e563cc7-4746-4cef-a6fb-aa4c1b80ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken==0.8.0 wandb==0.19.6 weave==0.51.33 docker==7.1.0 openai==1.61.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1109ed9-4c0d-4838-800a-8c8478110bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import docker\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import tiktoken\n",
    "import wandb\n",
    "import weave\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI() # OpenAI gets the API key from the env var\n",
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ae08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create containers on network\n",
    "container_name = \"nbtest_wandb\"\n",
    "try:\n",
    "    container = docker_client.containers.get(container_name)\n",
    "except docker.errors.NotFound:\n",
    "    # Ensure network exists\n",
    "    network_name = \"wandb_network\"\n",
    "    try:\n",
    "        network = docker_client.networks.get(network_name)\n",
    "    except docker.errors.NotFound:\n",
    "        network = docker_client.networks.create(network_name)\n",
    "\n",
    "    # Create container\n",
    "    container = docker_client.containers.run(\n",
    "        image=\"code-runner-client\",\n",
    "        name=container_name,\n",
    "        shm_size=\"512mb\",\n",
    "        restart_policy={\"Name\": \"unless-stopped\"},\n",
    "        network=network_name,\n",
    "        detach=True,\n",
    "        command=[\"/bin/sh\", \"-c\", \"sleep infinity\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start: Question / prompt\n",
    "question = \"\"\"\n",
    "What is the highest rated (according to IMDB) Isabelle Adjani feature film that is less than 2 hours and is available on Vudu (now called Fandango at Home) to buy or rent?\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63796e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Generate title\n",
    "system_prompt = \"\"\"\n",
    "You are an AI that generates concise, descriptive titles based on the given question.\n",
    "Your response must be in the format: <title>Generated title here</title>. \"\n",
    "Keep the title brief and relevant to the question.\n",
    "\n",
    "Title examples:\n",
    "Question: \"What are the best practices for securing a FastAPI backend?\"\n",
    "<title>What Securing FastAPI best practices</title>\n",
    "\n",
    "Question: \"What are the key considerations when designing an LLM evaluation framework?\"\n",
    "<title>Designing an LLM eval framework</title>\n",
    "\n",
    "Question: \"How do I optimize OpenAI API costs for large-scale applications?\"\n",
    "<title>Optimizing OpenAI API costs</title>\n",
    "\"\"\".strip()\n",
    "\n",
    "oai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
    "    ]\n",
    ")\n",
    "completion_response = oai_response.choices[0].message.content\n",
    "\n",
    "pattern = r'<title>(.*?)</title>'\n",
    "title = re.findall(pattern, completion_response)\n",
    "title = title[0]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee929201",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2) Generate plan\n",
    "system_prompt = \"\"\"\n",
    "You are an AI that generates a structured plan for answering a given question. Your response must be in the format: <planning>Generated plan here</planning>.\n",
    "Your plan should outline the logical steps and methodologies required to find the answer but should not provide the answer itself.\n",
    "\n",
    "Consider the following when planning:\n",
    "- The agent can execute Python code.\n",
    "- The agent can make web searches using an external service.\n",
    "- The agent can go to specific web pages to retrieve information.\n",
    "- The plan should break down the approach into discrete steps.\n",
    "\n",
    "Example:\n",
    "\n",
    "Question: \"How can I find the average temperature for a given city over the past month?\"\n",
    "<planning>\n",
    "1. Identify a reliable weather data API that provides historical temperature data.\n",
    "2. Structure an API call to fetch daily temperature data for the specified city over the past month.\n",
    "3. Parse the API response and extract temperature values.\n",
    "4. Compute the average temperature based on the extracted values.\n",
    "5. Return a structured response containing the computed average.\n",
    "</planning>\n",
    "\n",
    "Question: \"What are the most frequent words in a given text?\"\n",
    "<planning>\n",
    "1. Receive the input text.\n",
    "2. Preprocess the text by removing punctuation and converting it to lowercase.\n",
    "3. Tokenize the text into individual words.\n",
    "4. Count the frequency of each unique word.\n",
    "5. Sort words by frequency and return the top results.\n",
    "</planning>\n",
    "\n",
    "Keep your response clear and structured within the <planning> block.\n",
    "\"\"\".strip()\n",
    "\n",
    "oai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
    "    ]\n",
    ")\n",
    "completion_response = oai_response.choices[0].message.content\n",
    "\n",
    "pattern = r'<planning>(.*?)</planning>'\n",
    "plan = re.findall(pattern, completion_response, re.DOTALL)\n",
    "print(plan[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660a795-0e31-4a66-8220-1f7e359b4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_file = './context.json'\n",
    "context = \"\"\n",
    "if os.path.exists(context_file):\n",
    "    try:\n",
    "        with open(context_file, 'r') as f:\n",
    "            context_data = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON from context.json\")\n",
    "else:\n",
    "    context_data = False\n",
    "    print(\"No context.json file found. Continuing without previous context.\")\n",
    "\n",
    "# Prepare a system prompt that instructs the assistant on how to generate the answer.\n",
    "# This prompt references the question, planning, and context.\n",
    "system_prompt = \"\"\"\n",
    "You are an AI that generates a comprehensive answer to the given question using the provided planning and context.\n",
    "Follow these instructions:\n",
    "1. Combine the question, planning, and context to generate your response.\n",
    "2. If the context already contains an answer, simply output it wrapped in an <answer>...</answer> block.\n",
    "3. If additional validation or demonstration is needed, include any Python code within an <execute_python>...</execute_python> block.\n",
    "4. If external information is required, use <search>...</search> for a general search\n",
    "5. If external information from a specific page is required, use <website_url>...</website_url> to fetch data from a specific webpage.\n",
    "\n",
    "### Available Python libraries:\n",
    "The Python environment includes the following pre-installed libraries:\n",
    "`pandas`, `numpy`, `scipy`, `scikit-learn`, `scikit-image`, `matplotlib`, `seaborn`, `beautifulsoup4`, `requests`\n",
    "\n",
    "If additional libraries are needed, they can be installed using:\n",
    "\n",
    "<execute_python>\n",
    "import subprocess\n",
    "subprocess.run(\"pip install package_name\", shell=True)\n",
    "</execute_python>\n",
    "\n",
    "### Example formats:\n",
    "#### If the answer is found in the context:\n",
    "<answer>Your answer here</answer>\n",
    "\n",
    "#### If Python computation is required:\n",
    "<execute_python>\n",
    "# Some Python code for computation\n",
    "</execute_python>\n",
    "\n",
    "#### If a search lookup is required:\n",
    "<search>Query for the relevant information</search>\n",
    "\n",
    "#### If a specific website page URL lookup is required:\n",
    "<website_url>https://example.com/specific-page</website_url>\n",
    "\"\"\".strip()\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Question: {question}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Planning: {plan}\"}\n",
    "]\n",
    "if context_data:\n",
    "    for entry in context_data:\n",
    "        if \"type\" in entry and entry[\"type\"] != \"assistant\":\n",
    "            content = f'{entry[\"type\"]}: {entry[\"content\"]}'\n",
    "        else:\n",
    "            content = entry[\"content\"]\n",
    "        messages.append({\"role\": entry[\"role\"], \"content\": content})\n",
    "\n",
    "# Generate the final response using the OpenAI client.\n",
    "oai_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "final_response = oai_response.choices[0].message.content\n",
    "\n",
    "# Output the generated response.\n",
    "print(final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55a5ec-f160-4c94-8a30-2497d3bae9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to save parsed content to the context file\n",
    "def save_to_context_file(role, entry_type, content):\n",
    "    if not content.strip():  # Check if content is blank\n",
    "        return  # Do not save if content is blank\n",
    "    entry = {\"role\": role, \"type\": entry_type, \"content\": content}\n",
    "    if os.path.exists(context_file):\n",
    "        try:\n",
    "            with open(context_file, 'r') as f:\n",
    "                context_data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            context_data = []\n",
    "    else:\n",
    "        context_data = []\n",
    "\n",
    "    context_data.append(entry)\n",
    "\n",
    "    with open(context_file, 'w') as f:\n",
    "        json.dump(context_data, f, indent=4)\n",
    "\n",
    "# Function to remove matched content and tags from the response\n",
    "def remove_matched_content(response, pattern):\n",
    "    return re.sub(pattern, '', response, flags=re.DOTALL).strip()\n",
    "\n",
    "# Parse the response for different blocks\n",
    "answer_pattern = r'<answer>(.*?)</answer>'\n",
    "execute_python_pattern = r'<execute_python>(.*?)</execute_python>'\n",
    "search_pattern = r'<search>(.*?)</search>'\n",
    "website_url_pattern = r'<website_url>(.*?)</website_url>'\n",
    "\n",
    "# Extract and save answer block\n",
    "answer_match = re.search(answer_pattern, final_response, re.DOTALL)\n",
    "if answer_match:\n",
    "    # Save the remaining content as assistant\n",
    "    remaining_response = remove_matched_content(final_response, answer_pattern)\n",
    "    save_to_context_file(\"assistant\", \"assistant\" ,remaining_response)\n",
    "    # Save content\n",
    "    answer_content = answer_match.group(1).strip()\n",
    "    save_to_context_file(\"assistant\", \"answer\", answer_content)\n",
    "\n",
    "# Extract and save execute_python block\n",
    "execute_python_match = re.search(execute_python_pattern, final_response, re.DOTALL)\n",
    "if execute_python_match:\n",
    "    # Save the remaining content as assistant\n",
    "    remaining_response = remove_matched_content(final_response, execute_python_pattern)\n",
    "    save_to_context_file(\"assistant\", \"assistant\" ,remaining_response)\n",
    "    # Save content\n",
    "    execute_python_content = execute_python_match.group(1).strip()\n",
    "    save_to_context_file(\"assistant\", \"execute_python\", execute_python_content)\n",
    "\n",
    "# Extract and save search block\n",
    "search_match = re.search(search_pattern, final_response, re.DOTALL)\n",
    "if search_match:\n",
    "    # Save the remaining content as assistant\n",
    "    remaining_response = remove_matched_content(final_response, search_pattern)\n",
    "    save_to_context_file(\"assistant\", \"assistant\" ,remaining_response)\n",
    "    # Save content\n",
    "    search_content = search_match.group(1).strip()\n",
    "    save_to_context_file(\"assistant\", \"search\", search_content)\n",
    "\n",
    "# Extract and save website_url block\n",
    "website_url_match = re.search(website_url_pattern, final_response, re.DOTALL)\n",
    "if website_url_match:\n",
    "    # Save the remaining content as assistant\n",
    "    remaining_response = remove_matched_content(final_response, website_url_pattern)\n",
    "    save_to_context_file(\"assistant\", \"assistant\" ,remaining_response)\n",
    "    # Save content\n",
    "    website_url_content = website_url_match.group(1).strip()\n",
    "    save_to_context_file(\"assistant\", \"website_url\", website_url_content)\n",
    "# Check if none of the matches are found\n",
    "if not website_url_match and not search_match and not execute_python_match:\n",
    "    save_to_context_file(\"assistant\", \"message\", final_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf27b6-454d-4767-b090-2abb987274f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if search_match:\n",
    "    url = f\"https://s.jina.ai/{search_content}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\",\n",
    "        \"X-Engine\": \"direct\",\n",
    "        \"X-Retain-Images\": \"none\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    save_to_context_file(\"assistant\", \"search_result\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d05879-da29-4608-8e46-29686e39d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "if website_url_match:\n",
    "    url = f\"https://r.jina.ai/{website_url_content}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.getenv('JINA_API_KEY')}\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    save_to_context_file(\"assistant\", \"website_url_result\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd011f7-a1f4-45e6-8ce2-a70954f31f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if execute_python_match:\n",
    "    exec_result = container.exec_run(\n",
    "        cmd=[\"python\", \"-c\", execute_python_content], stdout=True, stderr=True\n",
    "    )\n",
    "    save_to_context_file(\"assistant\", \"execute_python_result\", exec_result.output.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c315b8-3085-4a06-a264-d713aa268612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051b1ae-2629-48d0-b314-4397334ba4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7d197-9cac-4581-a14a-163b995f6bde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
